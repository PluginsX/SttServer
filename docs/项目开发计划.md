# FastAPI + FunASR 本地语音识别服务开发计划

## 1. 项目概述

本项目旨在基于 FastAPI 框架与 FunASR 的 paraformer-zh-streaming 模型，开发一个本地部署的实时语音识别服务。该服务将完全兼容阿里云DashScope WebSocket API规范，支持中文普通话的实时流式语音识别，使得原本调用阿里云Paraformer实时语音识别服务的客户端代码无需修改即可无缝接入本地服务。

### 核心特性
- 100%兼容阿里云DashScope WebSocket API
- 支持中文普通话实时流式识别
- 基于paraformer-zh-streaming模型
- 使用FastAPI提供WebSocket服务
- 独立虚拟环境 ./venv

### 目标用户
- 需要本地部署语音识别服务的开发者
- 希望降低阿里云API调用成本的企业
- 对数据隐私有要求的场景

## 2. 技术栈与依赖

### 2.1 技术选型

| 组件 | 版本/选型 | 说明 |
|------|-----------|------|
| 后端框架 | FastAPI | 提供 WebSocket 接口 |
| 语音模型 | FunASR (paraformer-zh-streaming) | 核心流式语音识别引擎（中文普通话） |
| 推理引擎 | PyTorch | 模型推理引擎 |
| 音频处理 | 无需额外库 | WebSocket直接接收PCM流 |
| 协议标准 | 阿里云DashScope WebSocket API | 100%兼容标准 |
| 虚拟环境 | ./venv | Python 3.8+ 虚拟环境 |
| ASGI服务器 | Uvicorn | FastAPI生产环境服务器 |

### 2.2 依赖列表

```
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
websockets>=12.0
pydantic>=2.5.0
funasr>=1.0.0
torch>=2.0.0
numpy>=1.24.0
```

### 2.3 硬件要求

- CPU: 4核心以上
- 内存: 8GB以上
- GPU: NVIDIA RTX 4060 8GB（推荐）
- 存储: 10GB以上可用空间

## 3. 核心开发任务分解

### 阶段一：环境搭建与模型准备 (预计 2-3 天)

#### 1.1 环境配置 (0.5天)
- 创建Python 3.8+虚拟环境 `./venv`
- 安装依赖库：FastAPI、FunASR、PyTorch等
- 配置CUDA环境（如使用GPU）
- 验证环境配置正确性

#### 1.2 模型下载 (0.5天)
- 下载 paraformer-zh-streaming 模型
- 下载必要的配置文件和词典
- 验证模型文件完整性

#### 1.3 模型验证 (1天)
- 编写测试脚本验证模型基本功能
- 测试中文普通话识别效果
- 测试模型推理性能
- 测试GPU显存占用

#### 1.4 FunASR API研究 (1天)
- 查阅FunASR官方文档和源码
- 研究流式推理接口
- 准备备选方案（伪流式实现）

### 阶段二：协议解析与接口设计 (预计 3-4 天)

#### 2.1 协议分析 (1天)
- 深入研究阿里云DashScope WebSocket API
- 分析握手流程、指令格式、事件结构
- 参考 [Paraformer实时语音识别WebSocket API.md](Paraformer实时语音识别WebSocket API.md)
- 整理协议要点和注意事项

#### 2.2 WebSocket基础实现 (1天)
- 创建 WebSocket 端点：`/api-ws/v1/inference`
- 处理连接建立、消息接收与发送
- 实现鉴权跳过（本地部署无需Token）
- 实现连接超时处理

#### 2.3 音频缓冲区设计 (1天)
- 设计环形缓冲区结构
- 实现音频数据累积和分块
- 处理音频流的不均匀到达
- 实现缓冲区溢出保护

#### 2.4 协议解析与格式化 (1天)
- 实现run-task指令解析
- 实现finish-task指令解析
- 实现task-started事件格式化
- 实现result-generated事件格式化
- 实现task-finished事件格式化

### 阶段三：核心逻辑开发 (预计 4-5 天)

#### 3.1 流式推理集成 (2天)
- 将 FunASR 的流式推理接口与 WebSocket 数据流对接
- 实现音频数据的实时处理
- 处理中间结果和最终结果
- 实现推理队列管理

#### 3.2 状态机实现 (1天)
- 实现语音识别的状态控制：
  - IDLE → CONNECTED → TASK_STARTED → STREAMING → TASK_FINISHED → IDLE
  - ERROR状态处理
- 处理并发状态同步
- 实现状态转换日志

#### 3.3 结果格式化 (1天)
- 将 FunASR 返回的识别结果转换为阿里云DashScope协议格式
- 支持中间结果（sentence_end: false）和最终结果（sentence_end: true）
- 实现时间戳映射
- 处理置信度信息

#### 3.4 错误处理 (1天)
- 音频格式验证
- 模型推理失败处理
- WebSocket异常断开处理
- 实现错误事件返回

### 阶段四：测试与优化 (预计 3-4 天)

#### 4.1 功能测试 (1天)
- 编写模拟客户端
- 端到端测试验证协议兼容性
- 测试中文普通话识别效果
- 测试各种边界情况

#### 4.2 客户端库开发 (1天)
- 开发 Web 客户端库 AsrClient.js
- 开发 Python 客户端库 AsrClient.py
- 创建 Web 版本 Demo 页面
- 创建 Python 版本 Demo 服务
- 编写客户端库文档

#### 4.3 性能调优 (1天)
- 优化音频分块大小（建议200ms@16kHz）
- 优化缓冲区管理策略
- 降低首字延迟（目标 < 600ms）
- 优化内存使用

#### 4.4 压力测试 (1天)
- 长时间运行测试（24小时+）
- 高并发连接测试（5-10路）
- 异常断开重连测试
- 内存泄漏检测

#### 4.4 性能基准测试 (1天)
- 测量首字延迟
- 测量识别准确率
- 测量吞吐量
- 测量资源占用（CPU/GPU/内存）

## 4. 关键数据结构设计

### 4.1 WebSocket连接

- **URL**: `ws://localhost:8000/api-ws/v1/inference`
- **Headers**: 无需Authorization（本地部署）
- **子协议**: 无

### 4.2 run-task指令（客户端 → 服务端）

```json
{
  "header": {
    "action": "run-task",
    "task_id": "2bf83b9a-baeb-4fda-8d9a-xxxxxxxxxxxx",
    "streaming": "duplex"
  },
  "payload": {
    "task_group": "audio",
    "task": "asr",
    "function": "recognition",
    "model": "paraformer-realtime-v2",
    "parameters": {
      "format": "pcm",
      "sample_rate": 16000,
      "language_hints": ["zh"],
      "punctuation_prediction_enabled": true,
      "inverse_text_normalization_enabled": true
    },
    "input": {}
  }
}
```

**参数说明**:
- `task_id`: 32位UUID，整个会话中保持一致
- `format`: 音频格式，支持pcm、wav、mp3、opus、speex、aac、amr
- `sample_rate`: 采样率，支持任意值（paraformer-realtime-v2）
- `language_hints`: 语言提示，["zh"]表示中文普通话

### 4.3 finish-task指令（客户端 → 服务端）

```json
{
  "header": {
    "action": "finish-task",
    "task_id": "2bf83b9a-baeb-4fda-8d9a-xxxxxxxxxxxx",
    "streaming": "duplex"
  },
  "payload": {
    "input": {}
  }
}
```

### 4.4 task-started事件（服务端 → 客户端）

```json
{
  "header": {
    "task_id": "2bf83b9a-baeb-4fda-8d9a-xxxxxxxxxxxx",
    "event": "task-started",
    "attributes": {}
  },
  "payload": {}
}
```

### 4.5 result-generated事件（服务端 → 客户端）

**中间结果示例**:
```json
{
  "header": {
    "task_id": "2bf83b9a-baeb-4fda-8d9a-xxxxxxxxxxxx",
    "event": "result-generated",
    "attributes": {}
  },
  "payload": {
    "output": {
      "sentence": {
        "begin_time": 170,
        "end_time": null,
        "text": "你好世界",
        "sentence_end": false
      }
    }
  }
}
```

**最终结果示例**:
```json
{
  "header": {
    "task_id": "2bf83b9a-baeb-4fda-8d9a-xxxxxxxxxxxx",
    "event": "result-generated",
    "attributes": {}
  },
  "payload": {
    "output": {
      "sentence": {
        "begin_time": 170,
        "end_time": 920,
        "text": "你好世界。",
        "sentence_end": true,
        "words": [
          {
            "begin_time": 170,
            "end_time": 295,
            "text": "你好",
            "punctuation": ""
          },
          {
            "begin_time": 295,
            "end_time": 503,
            "text": "世界",
            "punctuation": "。"
          }
        ]
      }
    },
    "usage": {
      "duration": 1
    }
  }
}
```

**字段说明**:
- `end_time`: null表示中间结果，数值表示最终结果
- `sentence_end`: false表示中间结果，true表示最终结果
- `words`: 字级别时间戳（可选）

### 4.6 task-finished事件（服务端 → 客户端）

```json
{
  "header": {
    "task_id": "2bf83b9a-baeb-4fda-8d9a-xxxxxxxxxxxx",
    "event": "task-finished",
    "attributes": {}
  },
  "payload": {}
}
```

### 4.7 音频数据格式

- **类型**: WebSocket Binary Frame
- **编码**: PCM 16bit 小端序
- **声道**: 单声道 (Mono)
- **采样率**: 8000Hz 或 16000Hz（推荐）
- **分片大小**: 建议 3200 字节 (200ms @ 16kHz)

## 5. 通信流程时序

```
客户端                    服务端
  │                          │
  │──── WebSocket连接 ──────→│
  │←──── 101响应 ────────────│
  │                          │
  │──── run-task指令 ───────→│
  │                          │
  │←──── task-started事件 ───│
  │                          │
  │──── 音频数据(二进制) ────→│
  │←──── result-generated事件│ (中间结果)
  │                          │
  │──── 音频数据(二进制) ────→│
  │←──── result-generated事件│ (中间结果)
  │                          │
  │──── 音频数据(二进制) ────→│
  │←──── result-generated事件│ (最终结果)
  │                          │
  │──── finish-task指令 ────→│
  │←──── result-generated事件│ (最终结果，如有)
  │←──── task-finished事件 ──│
  │                          │
  │──── 关闭连接 ───────────→│
```

## 6. 项目目录结构

```
AsrServer/
├── venv/                    # 虚拟环境
│   ├── Scripts/
│   │   ├── activate.bat     # Windows激活脚本
│   │   └── python.exe      # Python解释器
│   └── Lib/
│       └── site-packages/  # 已安装的包
├── main.py                  # FastAPI应用入口
├── config.py                # 配置管理
├── requirements.txt         # 依赖列表
├── start.bat                # Windows启动脚本
├── .trae/                   # IDE配置
│   └── rules/
│       └── project_rules.md # 项目规则
├── Client/                  # 客户端库和 Demo
│   ├── Web/              # Web 客户端
│   │   ├── lib/
│   │   │   └── AsrClient.js
│   │   └── demo/
│   │       └── index.html
│   ├── Python/           # Python 客户端
│   │   ├── lib/
│   │   │   └── AsrClient.py
│   │   └── demo/
│   │       ├── app.py
│   │       ├── requirements.txt
│   │       └── start.bat
│   └── README.md         # 客户端库文档
├── Documents/               # 文档
│   ├── 项目通信协议.md
│   ├── 项目开发计划.md
│   └── Paraformer实时语音识别WebSocket API.md
├── src/                     # 源代码
│   ├── __init__.py
│   ├── websocket/
│   │   ├── __init__.py
│   │   └── handler.py       # WebSocket处理器
│   ├── protocol/
│   │   ├── __init__.py
│   │   ├── parser.py        # 协议解析
│   │   ├── formatter.py     # 结果格式化
│   │   └── types.py         # 数据类型定义
│   ├── audio/
│   │   ├── __init__.py
│   │   └── processor.py     # 音频处理器
│   ├── asr/
│   │   ├── __init__.py
│   │   └── model.py         # FunASR模型封装
│   └── state/
│       ├── __init__.py
│       └── session.py       # 会话状态管理
└── tests/                   # 测试
    ├── test_model.py      # 模型测试
    └── test_client.py    # 模拟客户端
```

## 7. 部署与运维

### 7.1 启动方式

#### 方式一：命令行启动
```bash
# 激活虚拟环境
venv\Scripts\activate

# 启动服务
uvicorn main:app --host 0.0.0.0 --port 8000
```

#### 方式二：使用启动脚本
```batch
@echo off
call venv\Scripts\activate.bat
uvicorn main:app --host 0.0.0.0 --port 8000
```

#### 方式三：生产环境启动
```bash
# 使用多个worker进程
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

### 7.2 资源监控

#### 监控指标
- GPU显存占用
- CPU使用率
- 内存使用量
- WebSocket连接数
- 识别延迟
- 识别准确率

#### 监控工具
- NVIDIA nvidia-smi（GPU监控）
- htop（系统资源监控）
- 自定义日志分析

### 7.3 日志记录

#### 日志级别
- DEBUG: 详细调试信息
- INFO: 一般信息（连接建立、任务完成等）
- WARNING: 警告信息（音频格式异常等）
- ERROR: 错误信息（推理失败等）

#### 日志内容
- WebSocket连接状态
- 识别错误信息
- 性能指标（首字延迟、吞吐量）
- 系统资源使用情况

### 7.4 配置管理

#### config.py 示例
```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # 服务配置
    host: str = "0.0.0.0"
    port: int = 8000
    
    # 模型配置
    model_path: str = "./models/paraformer-zh-streaming"
    device: str = "cuda"  # 或 "cpu"
    
    # 音频配置
    default_sample_rate: int = 16000
    default_format: str = "pcm"
    chunk_size: int = 3200  # 200ms @ 16kHz
    
    # 性能配置
    max_connections: int = 10
    connection_timeout: int = 300  # 秒
    
    class Config:
        env_file = ".env"

settings = Settings()
```

## 8. 风险与挑战

### 8.1 协议兼容性

**风险描述**: 阿里云DashScope WebSocket API协议细节较多，实现难度大

**影响程度**: 高

**应对措施**:
- 严格对照[Paraformer实时语音识别WebSocket API.md](Paraformer实时语音识别WebSocket API.md)实现
- 使用阿里云官方SDK作为参考
- 编写详细的测试用例验证协议兼容性
- 实现协议版本管理，便于后续升级

### 8.2 流式延迟

**风险描述**: FunASR paraformer-zh-streaming模型首字延迟控制困难

**影响程度**: 中

**应对措施**:
- 精细调整音频分块大小
- 优化缓冲区管理策略
- 使用GPU加速推理
- 实现模型预热机制
- 监控并优化各环节耗时

### 8.3 资源瓶颈

**风险描述**: 8G显存在处理多路并发流时可能成为瓶颈

**影响程度**: 中

**应对措施**:
- 做好并发数限制
- 实现连接队列管理
- 准备CPU推理降级方案
- 监控显存使用情况
- 优化模型内存占用

### 8.4 FunASR API不确定性

**风险描述**: FunASR流式推理API文档可能不完整

**影响程度**: 中

**应对措施**:
- 深入研究FunASR源码
- 查阅GitHub issues和讨论
- 准备"伪流式"备选方案
- 与FunASR社区保持沟通

### 8.5 稳定性问题

**风险描述**: 长时间运行可能出现内存泄漏或崩溃

**影响程度**: 中

**应对措施**:
- 实现完善的错误处理
- 进行长时间压力测试
- 实现自动重启机制
- 监控内存使用情况
- 定期释放资源

## 9. 验收标准

### 9.1 协议兼容性

- [ ] 客户端使用阿里云DashScope Paraformer实时语音识别API的代码，仅修改WebSocket URL（从`wss://dashscope.aliyuncs.com/api-ws/v1/inference`改为`ws://localhost:8000/api-ws/v1/inference`）即可连接到本地服务
- [ ] 支持完整的指令集：run-task、finish-task
- [ ] 支持完整的事件集：task-started、result-generated、task-finished
- [ ] 支持中间结果和最终结果返回
- [ ] 支持时间戳信息

### 9.2 功能要求

- [ ] 支持中文普通话实时流式识别
- [ ] 支持PCM格式音频输入
- [ ] 支持16kHz采样率
- [ ] 支持标点符号预测
- [ ] 支持数字转写（ITN）
- [ ] 支持连接超时处理
- [ ] 支持异常断开处理

### 9.3 性能要求

- [ ] 中文普通话实时识别准确率 > 95%
- [ ] 首字延迟 < 600ms
- [ ] 支持至少5路并发识别（取决于GPU显存）
- [ ] 内存占用稳定，无内存泄漏
- [ ] CPU使用率合理（< 80%）

### 9.4 稳定性要求

- [ ] 服务可稳定运行24小时以上
- [ ] 无内存泄漏
- [ ] 无崩溃
- [ ] 异常情况下能优雅降级
- [ ] 支持自动恢复

### 9.5 代码质量

- [ ] 代码结构清晰，模块划分合理
- [ ] 有完整的错误处理
- [ ] 有详细的日志记录
- [ ] 有必要的代码注释
- [ ] 符合Python代码规范（PEP 8）

## 10. 开发时间估算

### 10.1 详细时间分解

| 阶段 | 任务 | 预计时间 | 关键产出 |
|------|------|----------|----------|
| 阶段一 | 环境搭建与模型准备 | 2-3天 | 可运行的开发环境 |
| | 1.1 环境配置 | 0.5天 | 虚拟环境、依赖安装 |
| | 1.2 模型下载 | 0.5天 | 模型文件 |
| | 1.3 模型验证 | 1天 | 模型功能验证报告 |
| | 1.4 FunASR API研究 | 1天 | API使用文档 |
| 阶段二 | 协议解析与接口设计 | 3-4天 | WebSocket基础框架 |
| | 2.1 协议分析 | 1天 | 协议分析文档 |
| | 2.2 WebSocket基础实现 | 1天 | WebSocket端点 |
| | 2.3 音频缓冲区设计 | 1天 | 缓冲区实现 |
| | 2.4 协议解析与格式化 | 1天 | 协议处理模块 |
| 阶段三 | 核心逻辑开发 | 4-5天 | 完整识别功能 |
| | 3.1 流式推理集成 | 2天 | 推理引擎 |
| | 3.2 状态机实现 | 1天 | 状态机模块 |
| | 3.3 结果格式化 | 1天 | 结果格式化模块 |
| | 3.4 错误处理 | 1天 | 错误处理机制 |
| 阶段四 | 测试与优化 | 3-4天 | 可发布版本 |
| | 4.1 功能测试 | 1天 | 测试报告 |
| | 4.2 性能调优 | 1天 | 性能优化报告 |
| | 4.3 压力测试 | 1天 | 稳定性报告 |
| | 4.4 性能基准测试 | 1天 | 性能基准报告 |
| **总计** | | **12-16天** | |

### 10.2 时间缓冲

- 建议预留2-3天缓冲时间
- 用于处理不可预见的问题
- 用于最后的集成测试和文档完善

### 10.3 里程碑

| 里程碑 | 时间点 | 验收标准 |
|--------|--------|----------|
| M1: 环境就绪 | 第3天 | 模型验证通过 |
| M2: 协议实现 | 第7天 | WebSocket基础功能完成 |
| M3: 核心功能 | 第12天 | 端到端识别成功 |
| M4: 测试完成 | 第16天 | 所有测试通过 |

## 11. 参考文档

### 11.1 官方文档

- [Paraformer实时语音识别WebSocket API.md](Paraformer实时语音识别WebSocket API.md) - 阿里云官方API文档
- [项目通信协议.md](项目通信协议.md) - 项目协议说明
- FunASR官方文档: https://github.com/alibaba-damo-academy/FunASR
- FastAPI官方文档: https://fastapi.tiangolo.com/
- Uvicorn官方文档: https://www.uvicorn.org/

### 11.2 技术博客

- WebSocket协议详解
- 流式语音识别技术原理
- FastAPI最佳实践

### 11.3 社区资源

- FunASR GitHub Issues
- FastAPI GitHub Discussions
- Stack Overflow相关问答

## 12. 附录

### 12.1 术语表

| 术语 | 说明 |
|------|------|
| ASR | Automatic Speech Recognition，自动语音识别 |
| PCM | Pulse Code Modulation，脉冲编码调制 |
| WebSocket | 一种全双工通信协议 |
| DashScope | 阿里云大模型服务平台 |
| FunASR | 阿里达摩院开源的语音识别工具包 |
| Paraformer | 阿里达摩院研发的语音识别模型 |
| ITN | Inverse Text Normalization，逆文本正则化 |
| VAD | Voice Activity Detection，语音活动检测 |

### 12.2 常见问题

**Q1: 为什么选择paraformer-zh-streaming模型？**
A: 该模型是FunASR专门为中文普通话流式识别优化的模型，在准确率和延迟方面都有良好表现。

**Q2: 本地服务相比阿里云API有什么优势？**
A: 1) 无需API调用费用；2) 数据隐私保护；3) 可定制化程度高；4) 延迟更低。

**Q3: 如何处理并发连接？**
A: 使用FastAPI的异步特性，每个WebSocket连接在独立的协程中处理，支持多路并发。

**Q4: 如何优化首字延迟？**
A: 1) 使用GPU加速；2) 优化音频分块大小；3) 实现模型预热；4) 优化缓冲区管理。

**Q5: 是否支持其他语言？**
A: 当前版本仅支持中文普通话，后续可扩展支持其他语言。

### 12.3 版本历史

| 版本 | 日期 | 说明 |
|------|------|------|
| v1.0 | 2026-02-11 | 初始版本 |

---

**文档维护**: 本文档应随着项目进展持续更新，确保与实际开发进度保持一致。
